{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# news Crawling : url query 이용 \n",
    "- url : http://media.daum.net -> [배열이력]\n",
    "- url : https://news.daum.net/newsbox -> base url -> [특정 날짜] \n",
    "- url : https://news.daum.net/newsbox?regDate=20200505  -> [특정 페이지]\n",
    "- url : https://news.daum.net/newsbox?regDate=20200505&page=2\n",
    "- url : https://news.daum.net/newsbox?regDate=20200201&page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지설치\n",
    "import urllib.request as req # url 요청\n",
    "from bs4 import BeautifulSoup # html  파싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. url query 만들기\n",
    "- date = 2020,2,1 ~ 2020.2.29\n",
    "- page = 1~10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://news.daum.net/newsbox?regDate=20200229&page=10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base url + date\n",
    "base_url = \"https://news.daum.net/newsbox?regDate=\"\n",
    "date = list(range(20200201, 20200230))\n",
    "date # 20200201 ~ 20200229\n",
    "len(date) # 29\n",
    "\n",
    "\n",
    "\n",
    "# 20200201 ~ 20200229의 뉴스 url list 생성\n",
    "url_list = [ base_url + str(d) for d in date]\n",
    "# https://news.daum.net/newsbox?regDate=20200201\n",
    "\n",
    "\n",
    "\n",
    "# base url + date + page\n",
    "# 각 날짜의 뉴스별로 1~10page의 뉴스 url 생성\n",
    "page = list(range(1, 11)) \n",
    "page # 1 ~ 10\n",
    "\n",
    "pages = ['&page=' + str(p)   for p in page] \n",
    "pages # &page=1 ~ &page=10\n",
    "\n",
    "\n",
    "final_url = []\n",
    "\n",
    "\n",
    "for url in url_list : # base url + date = 29\n",
    "    for page in pages : # page1 ~ page10 = 10\n",
    "        final_url.append(url + page)\n",
    "        # https://news.daum.net/newsbox?regDate=20200201&page=1\n",
    "\n",
    "len(final_url) # 290 = 29 * 10\n",
    "final_url[0]\n",
    "# 'https://news.daum.net/newsbox?regDate=20200201&page=1'\n",
    "final_url[-1]\n",
    "# 'https://news.daum.net/newsbox?regDate=20200229&page=10'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crawlier 함수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['의협 \"감염병 위기경보 상향 제안..환자 혐오 멈춰야\"', \"'신종코로나 진원' 중국 후베이성 춘제연휴 13일까지 재연장\", '높아진 국가청렴도..제도개혁이 관건', '\"독일 공군기, 중국 우한서 100여명 태우고 본국으로\"', '이견 여전한 방위비 협상..이달 타결될까', '의사협회 \"감염위기 \\'심각\\'으로 상향을..위험국가 입국 제한도\"', '6년 만의 시진핑 방한에도 영향..\"3~4월은 어렵다\"', '진천군, 우한 교민 임시생활 국가인재개발원 일대 방역 강화(종합)', \"무사증 제주입국 중국인, 귀국 후 신종코로나 확진..'방역비상'\", '31년 한우물 판 \\'젊은 노포\\' \"전통만큼 중요한 건 변화\" [\\'창간 31\\' - 세계일보와 \\'동갑내기\\' 가게들]']\n"
     ]
    }
   ],
   "source": [
    "def Crawlier(url) : \n",
    "    # 1. url 요청\n",
    "    res = req.urlopen(url)\n",
    "    src = res.read() # source\n",
    "       \n",
    "    # 2. html 파싱\n",
    "    src = src.decode('utf-8')\n",
    "    html = BeautifulSoup(src, 'html.parser')\n",
    "        \n",
    "    # 3. tag[속성='값'] -> 'a[class=\"link_txt\"]'\n",
    "    links = html.select('a[class=\"link_txt\"]')   \n",
    "    \n",
    "    \n",
    "    one_page_data = [] # 빈 list\n",
    "    cnt = 0 \n",
    "    \n",
    "    for link in links :\n",
    "        link_str = str(link.string) # 내용 추출\n",
    "        cnt += 1\n",
    "        # print('cnt :', cnt) \n",
    "        # print('news :', link_str)\n",
    "        one_page_data.append(link_str.strip()) # 문장 끝 불용어 처리(\\n, 공백)\n",
    "    \n",
    "    return one_page_data[:40] # list\n",
    "\n",
    "# 1page만 crawling\n",
    "one_page_data = Crawlier(final_url[0])  # 2020. 02. 01 -> page1  \n",
    "len(one_page_data)  # 134 -> 40 \n",
    "type(one_page_data)  # list  \n",
    "\n",
    "\n",
    "\n",
    "# 해당 기사 추출 \n",
    "print(one_page_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 전체 기사 수집 : crwler 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['의협 \"감염병 위기경보 상향 제안..환자 혐오 멈춰야\"', \"'신종코로나 진원' 중국 후베이성 춘제연휴 13일까지 재연장\", '높아진 국가청렴도..제도개혁이 관건', '\"독일 공군기, 중국 우한서 100여명 태우고 본국으로\"', '이견 여전한 방위비 협상..이달 타결될까', '의사협회 \"감염위기 \\'심각\\'으로 상향을..위험국가 입국 제한도\"', '6년 만의 시진핑 방한에도 영향..\"3~4월은 어렵다\"', '진천군, 우한 교민 임시생활 국가인재개발원 일대 방역 강화(종합)', \"무사증 제주입국 중국인, 귀국 후 신종코로나 확진..'방역비상'\", '31년 한우물 판 \\'젊은 노포\\' \"전통만큼 중요한 건 변화\" [\\'창간 31\\' - 세계일보와 \\'동갑내기\\' 가게들]']\n"
     ]
    }
   ],
   "source": [
    "month_news = []\n",
    "page_cnt = 0\n",
    "\n",
    "# Crwler 함수 호출\n",
    "for url in final_url:\n",
    "    page_cnt += 1\n",
    "    # print('page :', page_cnt)\n",
    "    try : # url 없는 경우\n",
    "        one_page_news = Crawlier(url) # 1page news\n",
    "        # print('one page news')\n",
    "        # print(one_page_news)\n",
    "        \n",
    "        # month_news.append(one_page_news) # [[1page],[2page],...]\n",
    "        month_news.extend(one_page_news) # [1page ~ 299page]\n",
    "    except :\n",
    "        print('해당 url 없음 :',url)\n",
    "        \n",
    "\n",
    "\n",
    "len(final_url)\n",
    "len(month_news) # 29dayx10pagex40news = 11600\n",
    "print(month_news[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Binary file save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # list -> file save -> load(list) : 리스트 객체 유지 가능\n",
    "\n",
    "# file save\n",
    "file = open('data/news_data.pck', mode='wb')\n",
    "pickle.dump(month_news, file) \n",
    "file.close()\n",
    "\n",
    "# file load\n",
    "file = open('data/news_data.pck', mode='rb')\n",
    "month_news_crawling2 = pickle.load(file)\n",
    "month_news_crawling2\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
